{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa05baeb",
   "metadata": {},
   "source": [
    "Fine-tunes Hugging Face Transformers + PyTorch sentiment model on small Amazon-style reviews.\n",
    "\n",
    "Shows live training logs and plots the training loss curve üìâ.\n",
    "\n",
    "Tests predictions before and after fine-tuning so we can see the impact of training in real time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c02dd8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# üì¶ STEP 1: Install libraries\n",
    "# ============================\n",
    "!pip install transformers datasets evaluate accelerate matplotlib tf-keras -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0522129",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/navaneethakrishnanp/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    pipeline,\n",
    "    TrainerCallback\n",
    ")\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Small dataset\n",
    "data = {\n",
    "    \"text\": [\n",
    "        \"Amazing quality! I love this.\",\n",
    "        \"Not good, I expected better.\",\n",
    "        \"Terrible product, waste of money.\",\n",
    "        \"Awesome product and fast delivery!\",\n",
    "        \"Worst purchase ever.\",\n",
    "        \"I absolutely love it!\",\n",
    "        \"Not worth the price.\",\n",
    "        \"Fantastic quality and support.\"\n",
    "    ],\n",
    "    \"label\": [1, 0, 0, 1, 0, 1, 0, 1]\n",
    "}\n",
    "\n",
    "train_dataset = Dataset.from_dict({\n",
    "    \"text\": data[\"text\"][:6],\n",
    "    \"label\": data[\"label\"][:6]\n",
    "})\n",
    "test_dataset = Dataset.from_dict({\n",
    "    \"text\": data[\"text\"][6:],\n",
    "    \"label\": data[\"label\"][6:]\n",
    "})\n",
    "\n",
    "# Tokenizer + model\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=64)\n",
    "\n",
    "encoded_train = train_dataset.map(preprocess_function, batched=True)\n",
    "encoded_test = test_dataset.map(preprocess_function, batched=True)\n",
    "encoded_train = encoded_train.rename_column(\"label\", \"labels\")\n",
    "encoded_test = encoded_test.rename_column(\"label\", \"labels\")\n",
    "encoded_train.set_format(\"torch\")\n",
    "encoded_test.set_format(\"torch\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "# Metrics\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# Training args\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_strategy=\"steps\",  # show live logs\n",
    "    logging_steps=1,\n",
    "    save_strategy=\"no\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=3,  # reduced for demo\n",
    "    weight_decay=0.01,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# ‚úÖ Proper loss callback\n",
    "class LossHistoryCallback(TrainerCallback):\n",
    "    def __init__(self):\n",
    "        self.losses = []\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs and \"loss\" in logs:\n",
    "            self.losses.append(logs[\"loss\"])\n",
    "\n",
    "loss_history = LossHistoryCallback()\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_train,\n",
    "    eval_dataset=encoded_test,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[loss_history]\n",
    ")\n",
    "\n",
    "# Train\n",
    "trainer.train()\n",
    "\n",
    "# Plot loss\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(loss_history.losses, label=\"Training Loss\")\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show(block=False)  # ‚úÖ non-blocking plot\n",
    "\n",
    "# Inference\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "test_reviews = [\n",
    "    \"Not good, I expected better.\",\n",
    "    \"Amazing quality!\",\n",
    "    \"Worst purchase ever.\",\n",
    "    \"I love this product so much!\",\n",
    "    \"Terrible quality and very slow shipping.\",\n",
    "    \"Absolutely fantastic experience!\"\n",
    "]\n",
    "\n",
    "print(\"\\nüß™ Test predictions:\")\n",
    "for review in test_reviews:\n",
    "    res = sentiment_pipeline(review)[0]\n",
    "    print(f\"{review} ‚ûù {res['label']} ({res['score']:.2f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cc3271",
   "metadata": {},
   "source": [
    "Before fine-tuning: Some sentences like ‚ÄúNot good, I expected better‚Äù might be misclassified as positive.\n",
    "\n",
    "After fine-tuning: Predictions become more accurate.\n",
    "\n",
    "üìà Loss curve clearly shows how the model is learning over steps."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
